\subsection{802.11 Data Transmission}
\label{subsec:tx}

%% 802.11 data transmission protocol mainly consists of sequence number management,
%% acknowledgment and retransmission.
%% %
%% The goal of this section is two-fold.
%
We have three main goals in this section.  First, we show that our
verification framework can improve verification precision by inferring
the missing or extra packets using the argumented transition
framework.
%
Second, we study how the packet loss ratios affect the quality of the
verification.
%
Finally, we demonstrate the ability of our framework to detect true violations by manually introducing bugs in the \ns{} implementation and by showing the
precision and recall of violation detection.

\begin{figure*}[t!]
  \centering
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/scripts/MutationDUTJaccard3DFigure_0_10.pdf}
    \caption{$Pr_{ed} \in [0.05, 0.10, 0.15]$}
  \end{subfigure}\hspace*{0.01\textwidth}
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/scripts/MutationDUTJaccard3DFigure_0_30.pdf}
    \caption{$Pr_{ed} \in [0.20, 0.25, 0.30, 0.35]$}
  \end{subfigure}\hspace*{0.01\textwidth}
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/scripts/MutationDUTJaccard3DFigure_0_50.pdf}
    \caption{$Pr_{ed} \in [0.40, 0.45, 0.50]$}
  \end{subfigure}\hspace*{0.01\textwidth}
  \caption{\textbf{Jaccard Distance Between Mutation and DUT Traces.} For each
  data point, the mean of the 5 runs is used.}
  \label{fig:mutation_dut}
\end{figure*}

\begin{comment}
\begin{figure*}[t!]
  \centering
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/scripts/StepCount3DFigure_0_10.pdf}
    \caption{$Pr_{ed} \in [0.05, 0.10, 0.15]$}
  \end{subfigure}\hspace*{0.01\textwidth}
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/scripts/StepCount3DFigure_0_30.pdf}
    \caption{$Pr_{ed} \in [0.20, 0.25, 0.30, 0.35]$}
  \end{subfigure}\hspace*{0.01\textwidth}
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/scripts/StepCount3DFigure_0_50.pdf}
    \caption{$Pr_{ed} \in [0.40, 0.45, 0.50]$}
  \end{subfigure}\hspace*{0.01\textwidth}
  \caption{\textbf{Average Searching Step Per Packet.} For each data point, the mean of 5 runs
  is used.}
  \label{fig:cost}
\end{figure*}
\end{comment}


\subsubsection{Experimental Setup}

We set up one \wifi{} client device and one Access Point (AP), which act as the DUT
and endpoint respectively.
%
Another \wifi{} device is configured in monitor mode and acts as the sniffer.
%
The DUT and endpoint are configured to use
the IEEE 802.11g standard with both RTS/CTS and fragmentation disabled.
%
A Constant Bit
Rate (CBR) UDP traffic (54~Mbps) is generated from the DUT to the endpoint.
%
The UDP packet size is 1436 bytes, which results in a 1500 bytes \wifi{} packet.

In order to control the packet loss ratios between each pair of devices, we
developed a new propagation loss model for \ns{} called
\texttt{MatrixRandomPropagationLossModel}.
%
\sloppy{%
  Instead of a constant propagation
  loss as in existing \texttt{MatrixPropagationLossModel}, the signal propagation
  loss between a pair of nodes is determined by a binary random variable of two
  values: 0~dB (no loss) and 1000~dB (complete loss).
}
%
Therefore, any packet loss
probability can be achieved by adjusting the random variable distribution.
%
The
model supports both symmetric and asymmetric propagation losses.
%
We use
symmetric propagation loss in all our experiments.
%
Finally, pcap capture is enabled in both the DUT and the sniffer devices.


\subsubsection{Verifying Unmodified Implementation}

In NS-3's implementation of 802.11g protocol, the acknowledgment time out $T_o$
is 334~$\mu s$ and maximum retransmission count is 7.
%
We use the same parameters in our checker state machine.
%
Additionally, we set the maximum retransmission delay $T_m$ to be 15~ms to
tolerate the back off delay in 802.11 DCF and also any possible processing
delays.


Let $Pr_{ds}$, $Pr_{es}$ and $Pr_{ed}$ be the packet loss probability between
the DUT and sniffer, endpoint and sniffer, DUT and endpoint respectively.
%
We vary each probability from 0 to 0.5 (both inclusive) with 0.05
step.
%
For each loss ratio combination, we ran the experiment 5 times, and each run lasted 30 seconds.
%
In total, 6655 ($11^3\times 5$) pair of DUT and sniffer packet traces were
collected.

To establish the ground truth of violations, we first verify the DUT packet
traces using the \textit{original} state machine $S$.
%
This can be achieved by
disabling augmented transitions in our framework.
%
As expected, no violation is
detected in any DUT packet traces.

We then verify the sniffer traces using the augmented state machine $S^+$.
%
For the $NumMissing$ heuristic, we use $l=100$ and $k=Pr\times r\times l$ for $1.0 \le r \le 2.0$
with 0.2 step, and $Pr$ is $Pr_{ds}$ for the DUT and $Pr_{es}$ for the endpoint.
%
For the $GoBack(k)$ heuristic, we set $k=7$, which is the maximum number of transmissions
of a single packet.
%

We first report that for all sniffer traces collected with different packet loss
probabilities, no violation is reported, which demonstrates our framework's
ability to tolerate sniffer imperfection instead of raising false alarms.

Next, we present detailed analysis of the augmented transitions on the sniffer
traces.
%
The goal is to study for a given link packet loss probability ($Pr_{ed}$), how
the sniffer's packet loss properties ($Pr_{ds}$ and $Pr_{es}$) affect the
difference between mutation and the DUT trace.
%
For all following analysis, we divide the traces into three groups according to
$Pr_{ed}$: low ($0 \le Pr_{ed} \le 0.15$), medium
($0.20 \le Pr_{ed} \le 0.35$) and high ($0.40 \le Pr_{ed} \le 0.50$).

\begin{comment}
Figure~\ref{fig:consec_aug} shows the distribution of Maximum Consecutive
Augmented Transitions (MCAT) in the mutation trace. First, for a given system
loss ratio $Pr_{ed}$, the higher the sniffer packet loss probability, the larger
the MCAT. In particular, the MCAT peaks when the sniffer missed 50\% packets both
from the DUT and the EP. Second, when the system loss ratio gets higher, the
peak of MCAT decreases. This is due to the fact that the ratio of retransmission
packets increases when $Pr_{ed}$ gets higher. Since all the retransmission
packets with the same sequence number are identical, the uncertainty can be
resolved with potentially fewer retransmission packets than what the DUT
actually sent. In other words, the major uncertainty is the \textit{existence},
nor the \textit{number} of retransmission packets.
\end{comment}

The different between two packet traces can be quantified by the Jaccard distance
metric.

\begin{align}
  Jaccard(Tr_1, Tr_2) = \frac{Tr_1 \ominus Tr_2}{Tr_1 \cup Tr_2}
\end{align}
where $\ominus$ is the symmetric difference operator.
%
The distance is 0 if the
two traces are identical, and is 1 when the two traces are completely different.
%
The smaller the distance is, the more similar the two traces are.

A naive way to calculate the distance is to use the hash the $(t, p)$ pair for
set intersection and union operation.
%
However, it does not work for mutation
trace which contains fabricated packets with no actual payload.
%
Therefore, we use
a protocol specific canonical representation of packets when calculating the
distance.
%
In particular, the string \texttt{r\_DATA\_i\_t} represents the $t^{th}$
transmission of a data packet with sequence number $i$.
%
$r$ represents the round
of sequence numbers as it wraps after 4096.
%
And similarly \texttt{r\_Ack\_i\_t} is the corresponding acknowledgment packet.

Figure~\ref{fig:mutation_dut} shows the Jaccard Distance between mutation and
its corresponding DUT trace.
%
We make the following observations.
%
First, for a given system loss probability, the more packet the sniffer picks up,
the more similar the mutation trace is to the DUT trace.
%
Interestingly, $Pr_{ds}$ is the dominant factor between the two.
%
This is because retransmission packets of the same sequence number are
identical, hence it may require to infer less retransmission packets than that
were actually transmitted to unstuck the state machine.
%
We note, however, this
trend is protocol specific and may be not be generally applicate to other
protocols.
%
Second, as the system loss probability increases, the Jaccard distance increases
more rapidly as $Pr_{ds}$ increases.
%
This is because the ratio of retransmission
packet increases along with $Pr_{ds}$.


\begin{comment}

Finally, We evaluate the cost of resolving uncertainty. In particular, we use
the Average Search Steps Per Packet (ASSPP) as a metric to quantify the search
cost.  It is calculated by dividing the total number of search steps by the
number of packets in the packet trace. For DUT traces, ASSPP is always 1 since
there is not uncertainty. For sniffer traces, however, multiple search steps has
be to conducted to resolve the potential uncertainty of each packet in the
sniffer trace.



Figure~\ref{fig:cost} shows the distribution of ASSPP at different $Pr_{ed}$.
Similar to the case in Figure~\ref{fig:mutation_dut}, $Pr_{ds}$ plays a dominant
role in determine the searching cost. One interesting observation is that the
search cost peaks when $Pr_{ds}$ is high while $Pr_{es}$ is low. In such loss
probability combinations, sniffer misses many data packets from the DUT but
picks up lots of \textit{dangling} $Ack$ packets from the EP. Because the $Ack$
packet has neither sequence numbers nor retry flag, the searching algorithm had
a hard time resolving such uncertainty.
\end{comment}

\subsubsection{Introducing Bugs}

We have demonstrated that our framework can tolerate sniffer imperfection and
avoid raising false alarms.
%
The next question is, can it detect true violations?
%
To answer this question, we manually introduce several bugs in \ns{}
implementation that concerns various aspects of 802.11 data transmission
protocol.
%
More specifically, the bugs are:

\begin{itemize}
  \item \textbf{Sequence Number}\quad The DUT does not assign sequence number
    correctly. For example, it may increase sequence by 2 instead of 1, or it
    does not increase sequence number after certain packet, etc.
  \item \textbf{Semantic}\quad The DUT may retransmit even
    after receiving $Ack$, or does not retransmit when not receiving $Ack$.
\end{itemize}

We instrument the \ns{} implementation to embed instances of bugs in each
category. At each experiment run, we randomly decide whether and which bug to
introduce for each category. We fix $Pr_{ds}=Pr_{es}=0.1$ and vary $Pr_{ed}$
from 0.0 to 0.5 with 0.01 step. For each $Pr_{ed}$ value, we ran the experiment
100 times, of which roughly 75 experiments contained bugs. In total, 5100 pairs of
DUT and sniffer traces were collected.

\begin{figure}[t!]
  \centering
  \begin{subfigure}{0.48\textwidth}
  \includegraphics[width=\textwidth]{./figures/scripts/PrecisionFigure.pdf}
\end{subfigure}
  \begin{subfigure}{0.48\textwidth}
  \includegraphics[width=\textwidth]{./figures/scripts/RecallFigure.pdf}
\end{subfigure}
  \caption{\textbf{Precision and Recall of Violation Detection.}}
  \label{fig:precision}
\end{figure}

We use the DUT packet traces as ground truth of whether or not each experiment
run contains bugs.
%
For each $Pr_{ed}$ value, we calculate the precision and recall of violation
detection using the sniffer traces.
%
\begin{align}
  \text{Precision} = \frac{\{\text{Reported Bugs}\} \cap \{\text{True Bugs}\}}{\{\text{Reported Bugs}\}}\\
  \text{Recall} = \frac{\{\text{Reported Bugs}\} \cap \{\text{True Bugs}\}}{\{\text{True Bugs}\}}
\end{align}
%
The precision metric quantifies how \textit{useful} the validation results are ,
while the recall metric measures how \textit{complete} the validation results
are.


Figure~\ref{fig:precision} shows the validating precision and recall for various
$k$ values.
%
As expected, the more tolerant the search to sniffer
losses (larger $k$), the more precise the violation detection.
%
In particular,
when $k=30$, the precisions are 100\% for all $Pr_{ed}$ values.
%
Second, the recall is less sensitive to the choice of $k$.
%
Except for the extreme case when $k=30$, all other thresholds can report almost
all the violations.
